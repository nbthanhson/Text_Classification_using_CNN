{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Text-Classification_model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN5lEVdehhzCACCQor1IyP9"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"sLfyngegSa9P"},"source":["from tensorflow import keras\n","\n","#Load IMDB dataset\n","(train_data, train_labels), (test_data, test_labels) = keras.datasets.imdb.load_data()\n","\n","print('Training data: ', train_data.shape)\n","print('Training labels: ', train_labels.shape, train_labels)\n","train_zero = (train_labels == 0).sum()\n","train_one = (train_labels == 1).sum()\n","print('Number of 0 and 1 in train_labels: {} {}'.format(train_zero, train_one))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8io5UCV9ZxCI"},"source":["print('The first row in training data (length: {}): \\n'.format(len(train_data[0])), train_data[0])\n","print('\\nThe second row in training data (length: {}): \\n'.format(len(train_data[1])), train_data[1])\n","\n","lens = [len(train_data[i]) for i in range(len(train_data))]\n","max_length = max(lens)\n","min_length = min(lens)\n","print('\\nThe min and max length in train_data: {}, {}'.format(max_length, min_length))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dkRJN7-Xmbiy"},"source":["word2index = keras.datasets.imdb.get_word_index()\n","\n","word2index = dict([(key, value + 3) for (key, value) in word2index.items()])\n","word2index['<PAD>'] = 0\n","word2index['<START>'] = 1\n","word2index['<UNKNOWN>'] = 2\n","word2index['<UNUSED>'] = 3\n","\n","print('The length of word2index: ', len(word2index))\n","print('The word2index: \\n', word2index)\n","\n","index2word = dict([(value, key) for (key, value) in word2index.items()])\n","\n","print('\\nThe index2word:')\n","print('Sorted index: ', sorted(index2word.keys()))\n","for i in range(10):\n","    print(index2word[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Diiw0byo1JFY"},"source":["#Function to convert a sequence of int to a sequance of words\n","def getText(int_seq):\n","    text = ' '.join(index2word.get(i) for i in int_seq)\n","    return text\n","\n","print('The first review:')\n","print(getText(train_data[0]))\n","print('The label: ',train_labels[0])\n","\n","print('\\nThe last review:')\n","print(getText(train_data[len(train_data) - 1]))\n","print('The label: ', train_labels[len(train_labels) - 1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XUJl6WIu6YzP"},"source":["#Add PAD to train_data and test_data\n","train_data = keras.preprocessing.sequence.pad_sequences(train_data, maxlen = max_length, padding = 'post', value = word2index['<PAD>'])\n","test_data = keras.preprocessing.sequence.pad_sequences(test_data, maxlen = max_length, padding = 'post', value = word2index['<PAD>'])\n","\n","print('The first row of training data (length: {}): \\n'.format(len(train_data[0])), train_data[0])\n","\n","print('\\nThe last row of training data (length: {}): \\n'.format(len(train_data[len(train_data) - 1])), train_data[len(train_data) - 1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ViFIJ0h-_VYT"},"source":["from keras.layers import Embedding, Conv1D, MaxPool1D, GlobalAvgPool1D, GlobalMaxPool1D, Flatten, Dense\n","\n","vocal_size = len(word2index)\n","embedding_dim = 50\n","\n","model = keras.Sequential()\n","\n","#Add an Embedding layer\n","model.add(Embedding(input_dim = vocal_size, output_dim = embedding_dim, input_length = max_length))\n","\n","#Add a Convolutional layer\n","model.add(Conv1D(filters = 128, kernel_size = 3, activation = 'relu', input_shape = (None, max_length, embedding_dim)))\n","\n","#Add a Max Pooling layer\n","model.add(MaxPool1D(pool_size = 2))\n","\n","#Add a GlobalAvgPool1D layer\n","model.add(GlobalAvgPool1D())\n","\n","#Add the output layer\n","model.add(Dense(64, activation = 'relu'))\n","model.add(Dense(1, activation = 'sigmoid'))\n","\n","#Display model summary\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gyq0GPCiz9lc"},"source":["from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","\n","#Compile the model\n","model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","\n","#Early stop training\n","early_stopping = EarlyStopping(monitor = 'val_loss', patience = 10, verbose = 1)\n","\n","#Save the best model\n","best_model = ModelCheckpoint(filepath = 'Text_Classification_bestmodel.h5', monitor = 'val_loss', verbose = 1, save_best_only = True)\n","\n","#Reduce learning rate\n","reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 5, verbose = 1, min_lr = 0.001)\n","\n","#Start training\n","model_history = model.fit(train_data, train_labels,\n","                          batch_size = 512, epochs = 50, validation_split = 0.3,\n","                          callbacks = [early_stopping, best_model, reduce_lr],\n","                          shuffle = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cQDiVSwtHJfq"},"source":["#Load the best model\n","keras.models.load_model(filepath = 'Text_Classification_bestmodel.h5')\n","\n","model.evaluate(test_data, test_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yLHsmWDMDqw-"},"source":["import matplotlib.pyplot as plt\n","\n","# Get training loss and validation loss from model history\n","history_dict = model_history.history\n","loss = history_dict['loss']\n","val_loss = history_dict['val_loss']\n","\n","# Diplay a chart of training loss and validation loss\n","epochs = range(1, len(loss) + 1)\n","plt.plot(epochs, loss)\n","plt.plot(epochs, val_loss)\n","\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend(['Training loss', 'Val loss'], loc='center right')\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sFqclES8WSIn"},"source":["import matplotlib.pyplot as plt\n","\n","# Get training accuracy and validation loss from model history\n","history_dict = model_history.history\n","accuracy = history_dict['accuracy']\n","val_accuracy = history_dict['val_accuracy']\n","\n","# Diplay a chart of training accuracy and validation accuracy\n","epochs = range(1, len(accuracy) + 1)\n","plt.plot(epochs, accuracy)\n","plt.plot(epochs, val_accuracy)\n","\n","plt.title('Training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend(['Training accuracy', 'Val accuracy'], loc='center right')\n","\n","plt.show()"],"execution_count":null,"outputs":[]}]}